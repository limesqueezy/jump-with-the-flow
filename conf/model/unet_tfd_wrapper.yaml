_target_: jump_wtf.models.unet_wrapper.UNetWrapperKoopman
# dim:            [1, 48, 48]         # (C, H, W)
dim: [1, 28, 28]
num_channels:   64                  # base channels
num_res_blocks: 2

channel_mult: [1, 2, 2]
# channel_mult:   [1, 1, 2, 3, 4]      # <-- our custom 5-stage pattern
num_heads:      4
num_head_channels:      64
attention_resolutions:  "16"
dropout:       0.1

learn_sigma:     false
class_cond:     false
use_checkpoint: false
use_fp16:       false
use_new_attention_order:  false